{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map2loop:  Process plutons\n",
    "\n",
    "For each instruve but not sill polygon, find older neighbours and store decimated contact points. Also store dipping contact orientations (user defined, just because) with three possible sub-surface configurations:\n",
    "\n",
    "<b>saucers: \\\\_____/ <br>\n",
    "pancakes: /_____\\\\   \n",
    "domes: /‾\\\\</b>\n",
    "\n",
    "Saves out orientations and contact points, as well as updated group level stratigraphic column.<br>\n",
    "Doesn't account for faults yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\00073294\\Dropbox\\1_Jupyter_notebooks\\map2loop\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import features\n",
    "%matplotlib inline\n",
    "import sys, os\n",
    "from map2loop import m2l_utils\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from math import acos, sqrt, cos, sin, degrees, radians, fabs, atan2\n",
    "from shapely.geometry import shape, Polygon, LineString, Point\n",
    "## import geopandas as gpd\n",
    "#os.chdir('..')\n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters loaded from m2l_config.py:\n",
      "#ROI\n",
      "minlong=117 # should back calc from metre system\\n\",\n",
      "maxlong=118\n",
      "minlat=-23\n",
      "maxlat=-22\n",
      "\n",
      "step_out=0\n",
      "inset=0\n",
      "\n",
      "minx=500057\n",
      "maxx=603028\n",
      "miny=7455348\n",
      "maxy=7567953\n",
      "\n",
      "#CRS\n",
      "src_crs = {'init': 'EPSG:4326'}  \n",
      "dst_crs = {'init': 'EPSG:28350'} \n",
      "\n",
      "#PATH\n",
      "mname='hams3'\n",
      "geology_file='hams2_geol.shp'\n",
      "fault_file='GEOS_GEOLOGY_LINEARSTRUCTURE_500K_GSD.shp'\n",
      "structure_file='hams2_structure.shp'\n",
      "\n",
      "test_data_path='../test_data3/'\n",
      "\n",
      "\n",
      "#CODES\n",
      "gcode='GROUP_'\n",
      "dcode='DIP'\n",
      "ddcode='DIP_DIR'\n",
      "ccode='CODE'\n",
      "ncode='NAME'\n",
      "ocode='OBJECTID'\n",
      "gicode='GEOPNT_ID'\n",
      "r1code='ROCKTYPE1'\n",
      "r2code='ROCKTYPE2'\n",
      "tcode='TYPE'\n",
      "fcode='FEATURE'\n",
      "dscode='DESCRIPTN'\n",
      "ucode='UNITNAME'\n",
      "mincode='MIN_AGE_MA'\n",
      "maxcode='MAX_AGE_MA'\n",
      "sill_label='sill'\n",
      "intrusive_label='intrusive'\n",
      "fold_label='Fold axial trace'\n",
      "fault_label='Fault'\n",
      "bedding_label='Bed'\n",
      "\n",
      "#MODEL_EXTENTS\n",
      "model_base=-8200\n",
      "\n",
      "\n",
      "#DECIMATION\n",
      "orientation_decimate=0\n",
      "contact_decimate=25\n",
      "fault_decimate=5\n",
      "fold_decimate=5\n",
      "\n",
      "\n",
      "#INTERPOLATION\n",
      "gridx=100\n",
      "gridy=100\n",
      "scheme='scipy_rbf'\n",
      "dist_buffer=5\n",
      "intrusion_mode=0 # 1 all instrusions exluded from basal contacts, 0 only sills\n",
      "\n",
      "#ASSUMPTIONS\n",
      "pluton_dip=45\n",
      "pluton_form='saucers' #pluton_form='dontknow'  #saucers \\_____/  pancakes /_____\\   domes /â€¾â€¾â€¾â€¾â€¾\\  dontknow ???\n",
      "fault_dip=90\n",
      "\n",
      "#PATHS\n",
      "\n",
      "local_paths=False\n",
      "test_data_path='../test_data3/'\n",
      "graph_path=test_data_path+'graph/'\n",
      "tmp_path=test_data_path+'tmp/'\n",
      "data_path=test_data_path+'data/'\n",
      "dtm_path=test_data_path+'dtm/'\n",
      "output_path=test_data_path+'output/'\n",
      "vtk_path=test_data_path+'vtk/'\n",
      "m2m_cpp_path='../m2m_cpp/'\n",
      "\n",
      "fault_file=data_path+'GEOS_GEOLOGY_LINEARSTRUCTURE_500K_GSD.shp'\n",
      "structure_file=data_path+'hams2_structure.shp'\n",
      "geology_file=data_path+'hams2_geol.shp'\n",
      "\n",
      "fault_file_csv=fault_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "structure_file_csv=structure_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "geology_file_csv=geology_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "\n",
      "strat_graph_file=test_data_path+'graph/graph_strat.gml'\n",
      "\n",
      "dtm_file=dtm_path+mname+'_dtm.tif'\n",
      "dtm_reproj_file=dtm_path+mname+'_dtm_rp.tif'\n",
      "\n",
      "if(not os.path.isdir(tmp_path)):\n",
      "   os.mkdir(tmp_path)\n",
      "if(not os.path.isdir(output_path)):\n",
      "   os.mkdir(output_path)\n",
      "if(not os.path.isdir(dtm_path)):\n",
      "   os.mkdir(dtm_path)\n",
      "if(not os.path.isdir(dtm_path)):\n",
      "   os.mkdir(dtm_path)\n",
      "if(not os.path.isdir(vtk_path)):\n",
      "   os.mkdir(vtk_path)\n",
      "\n",
      "print('Default parameters loaded from m2l_config.py:')\n",
      "with open('../notebooks/m2l_config.py', 'r') as myfile:\n",
      "  data = myfile.read()\n",
      "  print(data)\n",
      "  myfile.close()\n",
      "print('\\nModify these parameters in the cell below')\n",
      "\n",
      "Modify these parameters in the cell below\n"
     ]
    }
   ],
   "source": [
    "%run -i \"../notebooks/m2l_config.py\"\n",
    "bbox=(minx,miny,maxx,maxy)\n",
    "\n",
    "pluton_dip=str(pluton_dip)\n",
    "\n",
    "dist_buffer=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters loaded from m2l_config.py:\n",
      "#ROI\n",
      "minlong=117 # should back calc from metre system\\n\",\n",
      "maxlong=118\n",
      "minlat=-23\n",
      "maxlat=-22\n",
      "\n",
      "step_out=0\n",
      "inset=0\n",
      "\n",
      "minx=500057\n",
      "maxx=603028\n",
      "miny=7455348\n",
      "maxy=7567953\n",
      "\n",
      "#CRS\n",
      "src_crs = {'init': 'EPSG:4326'}  \n",
      "dst_crs = {'init': 'EPSG:28350'} \n",
      "\n",
      "#PATH\n",
      "mname='hams3'\n",
      "geology_file='hams2_geol.shp'\n",
      "fault_file='GEOS_GEOLOGY_LINEARSTRUCTURE_500K_GSD.shp'\n",
      "structure_file='hams2_structure.shp'\n",
      "\n",
      "test_data_path='../test_data3/'\n",
      "\n",
      "\n",
      "#CODES\n",
      "gcode='GROUP_'\n",
      "dcode='DIP'\n",
      "ddcode='DIP_DIR'\n",
      "ccode='CODE'\n",
      "ncode='NAME'\n",
      "ocode='OBJECTID'\n",
      "gicode='GEOPNT_ID'\n",
      "r1code='ROCKTYPE1'\n",
      "r2code='ROCKTYPE2'\n",
      "tcode='TYPE'\n",
      "fcode='FEATURE'\n",
      "dscode='DESCRIPTN'\n",
      "ucode='UNITNAME'\n",
      "mincode='MIN_AGE_MA'\n",
      "maxcode='MAX_AGE_MA'\n",
      "sill_label='sill'\n",
      "intrusive_label='intrusive'\n",
      "fold_label='Fold axial trace'\n",
      "fault_label='Fault'\n",
      "bedding_label='Bed'\n",
      "\n",
      "#MODEL_EXTENTS\n",
      "model_base=-8200\n",
      "\n",
      "\n",
      "#DECIMATION\n",
      "orientation_decimate=0\n",
      "contact_decimate=25\n",
      "fault_decimate=5\n",
      "fold_decimate=5\n",
      "\n",
      "\n",
      "#INTERPOLATION\n",
      "gridx=100\n",
      "gridy=100\n",
      "scheme='scipy_rbf'\n",
      "dist_buffer=5\n",
      "intrusion_mode=0 # 1 all instrusions exluded from basal contacts, 0 only sills\n",
      "\n",
      "#ASSUMPTIONS\n",
      "pluton_dip=45\n",
      "pluton_form='saucers' #pluton_form='dontknow'  #saucers \\_____/  pancakes /_____\\   domes /â€¾â€¾â€¾â€¾â€¾\\  dontknow ???\n",
      "fault_dip=90\n",
      "\n",
      "#PATHS\n",
      "\n",
      "local_paths=False\n",
      "test_data_path='../test_data3/'\n",
      "graph_path=test_data_path+'graph/'\n",
      "tmp_path=test_data_path+'tmp/'\n",
      "data_path=test_data_path+'data/'\n",
      "dtm_path=test_data_path+'dtm/'\n",
      "output_path=test_data_path+'output/'\n",
      "vtk_path=test_data_path+'vtk/'\n",
      "m2m_cpp_path='../m2m_cpp/'\n",
      "\n",
      "fault_file=data_path+'GEOS_GEOLOGY_LINEARSTRUCTURE_500K_GSD.shp'\n",
      "structure_file=data_path+'hams2_structure.shp'\n",
      "geology_file=data_path+'hams2_geol.shp'\n",
      "\n",
      "fault_file_csv=fault_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "structure_file_csv=structure_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "geology_file_csv=geology_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "\n",
      "strat_graph_file=test_data_path+'graph/graph_strat.gml'\n",
      "\n",
      "dtm_file=dtm_path+mname+'_dtm.tif'\n",
      "dtm_reproj_file=dtm_path+mname+'_dtm_rp.tif'\n",
      "\n",
      "if(not os.path.isdir(tmp_path)):\n",
      "   os.mkdir(tmp_path)\n",
      "if(not os.path.isdir(output_path)):\n",
      "   os.mkdir(output_path)\n",
      "if(not os.path.isdir(dtm_path)):\n",
      "   os.mkdir(dtm_path)\n",
      "if(not os.path.isdir(dtm_path)):\n",
      "   os.mkdir(dtm_path)\n",
      "if(not os.path.isdir(vtk_path)):\n",
      "   os.mkdir(vtk_path)\n",
      "\n",
      "print('Default parameters loaded from m2l_config.py:')\n",
      "with open('../notebooks/m2l_config.py', 'r') as myfile:\n",
      "  data = myfile.read()\n",
      "  print(data)\n",
      "  myfile.close()\n",
      "print('\\nModify these parameters in the cell below')\n",
      "\n",
      "Modify these parameters in the cell below\n",
      "{'init': 'epsg:28350'}\n",
      "(186, 63) (186, 63)\n"
     ]
    }
   ],
   "source": [
    "test_data_path='../test_data3/'\n",
    "\n",
    "\n",
    "%run -i \"../test_data3/m2l_config.py\"\n",
    "\n",
    "\n",
    "geology = gpd.read_file(data_path+'hams2_geol.shp',bbox=bbox)\n",
    "print(geology.crs)\n",
    "\n",
    "geol_explode=m2l_utils.explode(geology)\n",
    "print(geology.shape, geol_explode.shape)\n",
    "roi = gpd.read_file(data_path+'hamms_roi.shp')\n",
    "\n",
    "geol_clip=m2l_utils.clip_shp(geol_explode,roi)\n",
    "\n",
    "\n",
    "dtm_reproj_file=dtm_path+'hams3_dtm_rp.tif'\n",
    "\n",
    "dtm = rasterio.open(dtm_reproj_file)\n",
    "\n",
    "f=open(tmp_path+'hams3_groups.csv',\"r\")\n",
    "groups =f.readlines()\n",
    "f.close\n",
    "\n",
    "ngroups=groups[0].split(\" \")\n",
    "ngroups=int(ngroups[1])\n",
    "\n",
    "orig_ngroups=ngroups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Wyloo_Group\n",
      "1 Shingle_Creek_Group\n",
      "2 Turee_Creek_Group\n",
      "3 Hamersley_Group\n",
      "4 Fortescue_Group\n",
      "5 A_s_PMI\n",
      "6 A_mgn_PRK\n",
      "7 A_b_PRK\n",
      "8 A_s_PRK\n",
      "9 A_mgn_PMI\n"
     ]
    }
   ],
   "source": [
    "gp_ages=np.zeros((1000,3))\n",
    "gp_names=np.zeros((1000),dtype='U25')\n",
    "\n",
    "for i in range (0,ngroups):\n",
    "    gp_ages[i,0]=-1e6 # group max_age\n",
    "    gp_ages[i,1]=1e6 # group min_age\n",
    "    gp_ages[i,2]=i # group index\n",
    "    gp_names[i]=groups[i+1].replace(\"\\n\",\"\")\n",
    "    print(i,gp_names[i])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../test_data3/output/ign_orientations_saucers.csv\n",
      "10 A_mgn_PMI_520\n",
      "11 A_mgn_PRK_32\n",
      "0 Wyloo_Group\n",
      "1 Shingle_Creek_Group\n",
      "2 Turee_Creek_Group\n",
      "3 Hamersley_Group\n",
      "4 Fortescue_Group\n",
      "5 A_s_PMI\n",
      "6 A_mgn_PRK\n",
      "7 A_b_PRK\n",
      "8 A_s_PRK\n",
      "9 A_mgn_PMI\n"
     ]
    }
   ],
   "source": [
    "allc=open(output_path+'all_ign_contacts.csv',\"w\")\n",
    "allc.write('GROUP_,id,x,y,z,code\\n')\n",
    "ac=open(output_path+'ign_contacts.csv',\"w\")\n",
    "ac.write(\"X,Y,Z,formation\\n\")\n",
    "ao=open(output_path+'ign_orientations_'+pluton_form+'.csv',\"w\")\n",
    "ao.write(\"X,Y,Z,azimuth,dip,polarity,formation\\n\")\n",
    "print(output_path+'ign_orientations_'+pluton_form+'.csv')\n",
    "j=0\n",
    "allpts=0\n",
    "ls_dict={}\n",
    "ls_dict_decimate={}\n",
    "id=0\n",
    "for ageol in geol_clip.iterrows(): # central polygon\n",
    "    ades=str(ageol[1][dscode])\n",
    "    arck=str(ageol[1][r1code])\n",
    "    if(str(ageol[1][gcode])=='None'):\n",
    "        agroup=str(ageol[1][ccode])\n",
    "    else:\n",
    "        agroup=str(ageol[1][gcode])\n",
    "    \n",
    "    for i in range(0,ngroups):\n",
    "        if (gp_names[i]==agroup):\n",
    "            if(int(ageol[1][maxcode]) > gp_ages[i][0]  ):\n",
    "                gp_ages[i][0] = ageol[1][maxcode]\n",
    "                #print(\"max\",agroup,gp_ages[i][0])\n",
    "            if(int(ageol[1][mincode]) < gp_ages[i][1]  ):\n",
    "                gp_ages[i][1] = ageol[1][mincode]\n",
    "                #print(\"min\",agroup,gp_ages[i][1])\n",
    "    if(intrusive_label in arck and sill_label not in ades):\n",
    "        newgp=str(ageol[1][ccode])+'_'+str(ageol[1][ocode])\n",
    "        #agp=str(ageol[1][gcode])\n",
    "        #print(newgp)\n",
    "        if(str(ageol[1][gcode])=='None'):\n",
    "            agp=str(ageol[1][ccode])\n",
    "        else:\n",
    "            agp=str(ageol[1][gcode])\n",
    "\n",
    "        if(not newgp  in gp_names):\n",
    "            #print(\"MMMMM\",ngroups,newgp)\n",
    "            gp_names[ngroups]=newgp\n",
    "            gp_ages[ngroups][0]=ageol[1][maxcode]\n",
    "            gp_ages[ngroups][1]=ageol[1][mincode]\n",
    "            gp_ages[ngroups][2]=ngroups\n",
    "            ngroups=ngroups+1\n",
    "        #else:\n",
    "            #print(\"-----\",ngroups,newgp)\n",
    "            \n",
    "        neighbours=[]\n",
    "        j+=1\n",
    "        central_age=ageol[1][mincode]    #absolute age of central polygon\n",
    "        central_poly=ageol[1].geometry\n",
    "        for bgeol in geol_clip.iterrows(): #potential neighbouring polygons  \n",
    "            if(ageol[1].geometry!=bgeol[1].geometry): #do not compare with self\n",
    "                if (ageol[1].geometry.intersects(bgeol[1].geometry)): # is a neighbour\n",
    "                    neighbours.append([(bgeol[1][ccode],bgeol[1][mincode],bgeol[1][r1code],bgeol[1][dscode],bgeol[1].geometry)])  \n",
    "        #display(neighbours)\n",
    "        if(len(neighbours) >0):\n",
    "            for i in range (0,len(neighbours)):\n",
    "                if((intrusive_label in neighbours[i][0][2] and sill_label not in ades) \n",
    "                   #or ('intrusive' not in neighbours[i][0][2]) and neighbours[i][0][1] > central_age ): # neighbour is older than central\n",
    "                   or (intrusive_label not in neighbours[i][0][2]) and neighbours[i][0][1]  ): # neighbour is older than central\n",
    "                    #print(ageol[1][ccode],neighbours[i][0][0])\n",
    "                    older_polygon=neighbours[i][0][4]\n",
    "                    if(not central_poly.is_valid ):\n",
    "                        central_poly = central_poly.buffer(0)\n",
    "                    if(not older_polygon.is_valid):\n",
    "                        older_polygon = older_polygon.buffer(0)\n",
    "                    LineStringC = central_poly.intersection(older_polygon)\n",
    "                    if(LineStringC.wkt.split(\" \")[0]=='GEOMETRYCOLLECTION' or \n",
    "                       LineStringC.wkt.split(\" \")[0]=='MULTIPOLYGON' or\n",
    "                       LineStringC.wkt.split(\" \")[0]=='POLYGON'): #ignore polygon intersections for now, worry about them later!\n",
    "                        #print(\"debug:GC,MP,P\")\n",
    "                        continue\n",
    "\n",
    "                    elif(LineStringC.wkt.split(\" \")[0]=='MULTILINESTRING'):\n",
    "                        k=0\n",
    "                        #print(\"lenlenlen\",len(LineStringC))\n",
    "\n",
    "                        #display(LineStringC)\n",
    "                        ls_dict[id] = {\"id\": id,ccode:newgp,gcode:newgp, \"geometry\": LineStringC}\n",
    "                        id=id+1\n",
    "                        for lineC in LineStringC: #process all linestrings\n",
    "                            #if(contact_decimate!=0): #decimate to reduce number of points\n",
    "                            if(m2l_utils.mod_safe(k,contact_decimate)==0 or k==int((len(LineStringC)-1)/2) or k==len(LineStringC)-1): #decimate to reduce number of points, but also take second and third point of a series to keep gempy happy\n",
    "                                locations=[(lineC.coords[0][0],lineC.coords[0][1])] #doesn't like point right on edge?\n",
    "                                #print(k,type(lineC))\n",
    "                                if(lineC.coords[0][0] > dtm.bounds[0] and lineC.coords[0][0] < dtm.bounds[2] and  \n",
    "                                   lineC.coords[0][1] > dtm.bounds[1] and lineC.coords[0][1] < dtm.bounds[3]):       \n",
    "                                        height=m2l_utils.value_from_raster(dtm,locations)\n",
    "                                        ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+height+\",\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                        ac.write(ostr)\n",
    "                                        allc.write(agp+\",\"+str(ageol[1][ocode])+\",\"+ostr)\n",
    "                                        ls_dict_decimate[allpts] = {\"id\": allpts,ccode:newgp,gcode:newgp, \"geometry\": Point(lineC.coords[0][0],lineC.coords[0][1])}\n",
    "                                        allpts+=1 \n",
    "                                else:\n",
    "                                    continue\n",
    "                                    #print(\"debug:edge points\")\n",
    "                            else:\n",
    "                                if(lineC.coords[0][0] > dtm.bounds[0] and lineC.coords[0][0] < dtm.bounds[2] and  \n",
    "                                        lineC.coords[0][1] > dtm.bounds[1] and lineC.coords[0][1] < dtm.bounds[3]):       \n",
    "                                    height=m2l_utils.value_from_raster(dtm,locations)\n",
    "                                    ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+height+\",\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                    #ls_dict_decimate[allpts] = {\"id\": id,\"CODE\":ageol[1]['CODE'],\"GROUP_\":ageol[1]['GROUP_'], \"geometry\": Point(lineC.coords[0][0],lineC.coords[0][1])}\n",
    "                                    allc.write(agp+\",\"+str(ageol[1][ocode])+\",\"+ostr)\n",
    "                                    allpts+=1\n",
    "                            \n",
    "                            #print(m2l_utils.mod_safe(k,contact_decimate))\n",
    "                            if(m2l_utils.mod_safe(k,contact_decimate)==0 or k==int((len(LineStringC)-1)/2) or k==len(LineStringC)-1): #decimate to reduce number of points, but also take second and third point of a series to keep gempy happy\n",
    "                                dlsx=lineC.coords[0][0]-lineC.coords[1][0]\n",
    "                                dlsy=lineC.coords[0][1]-lineC.coords[1][1]\n",
    "                                lsx=dlsx/sqrt((dlsx*dlsx)+(dlsy*dlsy))\n",
    "                                lsy=dlsy/sqrt((dlsx*dlsx)+(dlsy*dlsy))                                        \n",
    "\n",
    "                                locations=[(lineC.coords[0][0],lineC.coords[0][1])]\n",
    "                                height= m2l_utils.value_from_raster(dtm,locations)\n",
    "                                azimuth=(180+degrees(atan2(lsy,-lsx)))%360 #normal to line segment\n",
    "                                testpx=lineC.coords[0][0]+lsy # pt just a bit in/out from line\n",
    "                                testpy=lineC.coords[0][0]+lsx\n",
    "\n",
    "                                for cgeol in geol_clip.iterrows(): # check on direction to dip\n",
    "                                    if LineString(central_poly.exterior.coords).contains(Point(testpx, testpy)):\n",
    "                                        azimuth=(azimuth-180)%360\n",
    "                                        break\n",
    "                                if(pluton_form=='saucers'):\n",
    "                                    ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+str(height)+\",\"+str(azimuth)+\",\"+str(pluton_dip)+\",1,\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                elif(pluton_form=='domes'):\n",
    "                                    azimuth=(azimuth-180)%360\n",
    "                                    ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+str(height)+\",\"+str(azimuth)+\",\"+str(pluton_dip)+\",0,\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                elif(pluton_form=='dontknow'):\n",
    "                                    ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+str(height)+\",\"+str(azimuth)+\",\"+str(pluton_dip)+\",0,\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                else: #pluton_form == pancakes\n",
    "                                    azimuth=(azimuth-180)%360\n",
    "                                    ostr=str(lineC.coords[0][0])+\",\"+str(lineC.coords[0][1])+\",\"+str(height)+\",\"+str(azimuth)+\",\"+str(pluton_dip)+\",1,\"+newgp.replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "                                    \n",
    "                                ao.write(ostr)\n",
    "\n",
    "                            k+=1\n",
    "                    elif(LineStringC.wkt.split(\" \")[0]=='LINESTRING'): # apparently this is not needed\n",
    "                        #print(\"debug:LINESTRING\")\n",
    "                        k=0\n",
    "                        for pt in LineStringC.coords: #process one linestring\n",
    "                            #if(i%contact_decimate==0): #decimate to reduce number of points\n",
    "                            #print(\"ls\",pt)\n",
    "                            k+=1\n",
    "                    elif(LineStringC.wkt.split(\" \")[0]=='POINT'): # apparently this is not needed\n",
    "                        #print(\"debug:POINT\")\n",
    "                        #print(\"pt\",LineStringC.coords)\n",
    "                        k+=1\n",
    "                    else:\n",
    "                        #print(LineStringC.wkt.split(\" \")[0]) # apparently this is not needed\n",
    "                        k+=1\n",
    "ac.close()\n",
    "ao.close()\n",
    "allc.close()\n",
    "\n",
    "#print(ngroups)\n",
    "#for i in range (0,ngroups):\n",
    "#    print(i,gp_names[i])\n",
    "\n",
    "#display(gp_ages[:ngroups])\n",
    "#display(gp_names[:ngroups])\n",
    "\n",
    "#ga=gp_ages[:ngroups]\n",
    "#print(\"XXXXXXXXXXXXX\",ga)\n",
    "#f=ga[:,0].argsort()\n",
    "#display(f)\n",
    "  \n",
    "an=open('../test_data3/tmp/hams3_groups2.csv',\"w\")\n",
    "an.write('1 '+str(ngroups)+'\\n')\n",
    "for i in range (orig_ngroups,ngroups):\n",
    "    print(i,gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "    an.write(gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+'\\n')\n",
    "    gp=open('../test_data3/tmp/'+gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+'.csv',\"w\")\n",
    "    gp.write('1 1\\n'+gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+'\\n')\n",
    "    gp.close()\n",
    "for i in range (0,orig_ngroups):\n",
    "    print(i,gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "    an.write(gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+'\\n')\n",
    "an.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 A_mgn_PMI_520\n",
      "11 A_mgn_PRK_32\n"
     ]
    }
   ],
   "source": [
    "all_sorts=pd.read_csv('../test_data3/tmp/hams3_all_sorts.csv',\",\")\n",
    "\n",
    "as_2=open('../test_data3/tmp/hams3_all_sorts.csv',\"r\")\n",
    "contents =as_2.readlines()\n",
    "as_2.close\n",
    "\n",
    "all_sorts_file=open('../test_data3/tmp/hams3_all_sorts2.csv',\"w\")\n",
    "all_sorts_file.write('index,group number,index in group,number in group,code,group\\n')\n",
    "j=1\n",
    "for i in range (orig_ngroups,ngroups):\n",
    "    index=str(int(all_sorts.iloc[len(all_sorts)-1]['index'])+j)\n",
    "    group_number=str(int(all_sorts.iloc[len(all_sorts)-1]['group number'])+j)\n",
    "    print(i,gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "    ostr=index+\",\"+group_number+\",1,1,\"+gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+\",\"+gp_names[i].replace(\" \",\"_\").replace(\"-\",\"_\")+\"\\n\"\n",
    "    all_sorts_file.write(ostr)\n",
    "    j=j+1\n",
    "\n",
    "for i in range(1,len(all_sorts)+1):    \n",
    "    all_sorts_file.write(contents[i])\n",
    "    \n",
    "all_sorts_file.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=all_sorts.iloc[1]\n",
    "print(x,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
