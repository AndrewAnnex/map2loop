{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiscale Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current geologic modelling allows building a single model at a predetermined scale which is limited to that specific purpose and have an inherent risk to be used to make other assessments. This motivates us to research how to properly subsample geologic data to be able to automatically generate multiscale models that change as we try to answer different geological questions and as we visualize different scales.\n",
    "<img src='../graphics/multiscale modelling1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current workflow we are working on covers the following steps: <br>\n",
    "<img src='../graphics/multiscale modelling.png'>\n",
    "This notebook will cover the first three steps.\n",
    "The last three steps will be tacked in the map2loop notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Filtering  + Vector Simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:34.567940Z",
     "start_time": "2020-03-19T09:09:31.492428Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from map2loop import m2l_subsampling \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:34.584897Z",
     "start_time": "2020-03-19T09:09:34.573924Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i \"../test_data_vector/m2l_subsampling_config.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Western Australia dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:35.363106Z",
     "start_time": "2020-03-19T09:09:34.591879Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wa = gpd.read_file(western_australia,bbox=(115,-30,118,-25))\n",
    "#wa.fillna('empty', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are mutiple fields that we can use to filter our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:35.399955Z",
     "start_time": "2020-03-19T09:09:35.368045Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in wa.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:41.821213Z",
     "start_time": "2020-03-19T09:09:35.405940Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "ax1=wa.plot(column='WATECTUNIT',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=wa.plot(column='GROUP_',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "ax3=wa.plot(column='FORMATION',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax3)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:47.945442Z",
     "start_time": "2020-03-19T09:09:41.821213Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "ax1=wa.plot(column='CODE',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=wa.plot(column='UNITNAME',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "ax3=wa.plot(column='DESCRIPTN',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax3)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will be working with a smaller dataset in the Yalgoo-Singleton Greenstone Belt. It has a rich data set which includes the recent Geological Survey of Western Australia (GSWA) 1:100K geologic mapping data.<br><br> The Yalgoo-Singleton is a highly mineralized, geologically complex, largely heterogenous greenstone belt located at the western Youanmi Terrane, Yilgarn Craton. It surrounds the Yalgoo Dome which is a prominent, 100 km long, elliptical granitic dome made of a concentric core-rim distribution of a migmatite core and granitoid intrusions.<br><br>\n",
    "The area is also strucutrally affected by a 1–2 km wide high-strain zone, the Badja décollement which juxtaposes the greenstones against the granitic dome. Transpressive shear zones to the east host syn-tectonic metagranitic suites. <br><br> Finnaly, the the Yalgoo Dome, syn-tectonic granites and the transpressive shear zones to the eas are intruded by post-tectonic granites intruded.\n",
    "<img src='../graphics/ygsb.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:49.114237Z",
     "start_time": "2020-03-19T09:09:47.945442Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ygsb = gpd.read_file(geology_file)\n",
    "ygsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how different hierarchical filter would vary how we visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:51.745779Z",
     "start_time": "2020-03-19T09:09:49.122214Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "ax1=ygsb.plot(column='CODE',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=ygsb.plot(column='UNITNAME',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "ax3=ygsb.plot(column='SUPERGROUP',figsize=(7,7), edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax3)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscale by UNITNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, let's try to model at the unit scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:52.642005Z",
     "start_time": "2020-03-19T09:09:51.750766Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m2l_subsampling.upscale_by (ygsb, 'UNITNAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we simply geometrically aggregate the polygons with the same unit name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:54.868247Z",
     "start_time": "2020-03-19T09:09:52.645998Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m2l_subsampling.vector_aggregate (ygsb, 'UNITNAME', 'geometry', aggregate_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step involves simplifying the vectors while: <br>\n",
    "1. retaining critical points that define data points and/or salient features <br>\n",
    "2. preserving overall shape <br>\n",
    "3. preserving spatial arrangement and topological relationship with adjacent vectors <br>\n",
    "4.\tavoiding topological errors and self-intersections with itself or other vectors <br>\n",
    "5. balancing area gain and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:09:56.330634Z",
     "start_time": "2020-03-19T09:09:54.868499Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aggregate = gpd.read_file(aggregate_file)\n",
    "simplify_false=aggregate.simplify(1000, preserve_topology=False)\n",
    "simplify_true=aggregate.simplify(1000, preserve_topology=True)\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 16))\n",
    "ax1=simplify_false.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=simplify_true.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplifcation above, the left one shows the output from using Ramer-Douglas-Peucker (RDP). It is the most well-known vector simplification method as it is easy to implement and its recursive nature lends to a hierarchical structure for multi-scale simplification. It is fast and efficient  for data compression, eliminating redundant details, reducing the number of points used to represent them ( Ramer, 1972; Douglas and Peucker, 1973). \n",
    "![SegmentLocal](../graphics/rdp.gif \"Segment\")\n",
    "The algorithm begins by connecting the endpoints of a line with a trend line. The distance of each vertex to the trend line is then measured perpendicularly. Vertices closer to the line than the tolerance bandwidth error are eliminated. The line is then divided by the vertex farthest from the trend line, which makes two new trend lines. The remaining vertices are measured against these lines, and the process continues until all vertices within the tolerance are eliminated.\n",
    "\n",
    "The simplification in the right is using the Visvalignam-Whyatt (VW) algorithm. It is more intuitive, has less perceptible change and preserves shape more precisely.\n",
    "![SegmentLocal](../graphics/vw.gif \"Segment\")\n",
    "The principle of the algorithm is to select the vertices to delete (the less characteristic ones) rather than choosing the vertices to keep (in the Douglas and Peucker algorithm). The selection of vertices to delete is an iterative process, and at each iteration, the triangles formed by three consecutive vertices are computed. If the area of the smallest triangle is smaller than an area tolerance threshold, the middle vertex is deleted, and another iteration starts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Visvalignam-Whyatt algorithm is more suited for geological information, where the shapes geologists draw actually contain geological information and interpretation, the algorithm has been modified to preserve topological relationship and proximity to adjacent/neighboring polygons\n",
    "by keeping junctions between polygons and planar self-intersections.\n",
    "\n",
    "Let's take a look at these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:00.089473Z",
     "start_time": "2020-03-19T09:09:56.332187Z"
    }
   },
   "outputs": [],
   "source": [
    "m2l_subsampling.vector_simplify (aggregate_file, simplified_file, 1000)\n",
    "simplified = gpd.read_file(simplified_file)\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 16))\n",
    "ax1=aggregate.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=simplified.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "plt.figure()\n",
    "m2l_subsampling.CountNodes (aggregate_file)\n",
    "m2l_subsampling.CountNodes (simplified_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using the threshold=1000 (from the previous algorithms), the modified VW algorithm visually maintains the same overall shape and topological relationship while reducing the nodes by ~11%. <br>\n",
    "Now let's test how much more reduction we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:29.740316Z",
     "start_time": "2020-03-19T09:10:00.094458Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_a, 100000)\n",
    "b=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_b, 1000000)\n",
    "c=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_c, 2800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:30.281368Z",
     "start_time": "2020-03-19T09:10:29.740316Z"
    }
   },
   "outputs": [],
   "source": [
    "a=gpd.read_file(simplified_file_a)\n",
    "b=gpd.read_file(simplified_file_b)\n",
    "c=gpd.read_file(simplified_file_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:32.599855Z",
     "start_time": "2020-03-19T09:10:30.286331Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "ax1=a.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=b.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "ax3=c.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax3)\n",
    "plt.figure()\n",
    "m2l_subsampling.CountNodes (simplified_file_a)\n",
    "m2l_subsampling.CountNodes (simplified_file_b)\n",
    "m2l_subsampling.CountNodes (simplified_file_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that we can reduce up to a tolerance of 2.8 km2, reducing 93% on the vertices before losing topology. Now let's try to push that a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:39.686942Z",
     "start_time": "2020-03-19T09:10:32.603815Z"
    }
   },
   "outputs": [],
   "source": [
    "d=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_d, 2850000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oops!   \n",
    "\n",
    "That error means that we are losing geometry and topological relationship on one polygon. We can do further simplification if we set the tolerance to be different for each polygon instead of using a global threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:39.688969Z",
     "start_time": "2020-03-19T09:09:31.584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ygsb2 = gpd.read_file(geology_file2)\n",
    "plot=ygsb.plot(column='UNITNAME',figsize=(5,5), edgecolor='#000000',linewidth=0.2, legend=True, cmap='Set2')\n",
    "aggregate = gpd.read_file(aggregate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:10:39.688969Z",
     "start_time": "2020-03-19T09:09:31.588Z"
    }
   },
   "outputs": [],
   "source": [
    "a=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_a, 100000)\n",
    "b=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_b, 1000000)\n",
    "c=m2l_subsampling.vector_simplify (aggregate_file, simplified_file_c, 2800000)\n",
    "a=gpd.read_file(simplified_file_a)\n",
    "b=gpd.read_file(simplified_file_b)\n",
    "c=gpd.read_file(simplified_file_c)\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 16))\n",
    "ax1=a.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax1)\n",
    "ax2=b.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax2)\n",
    "ax3=c.plot(edgecolor='#000000',linewidth=0.2, cmap='Set2', ax=ax3)\n",
    "plt.figure()\n",
    "m2l_subsampling.CountNodes (simplified_file_a)\n",
    "m2l_subsampling.CountNodes (simplified_file_b)\n",
    "m2l_subsampling.CountNodes (simplified_file_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
