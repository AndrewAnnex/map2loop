{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map2loop: From geology layers to outputs to various 3D modelling programs- Hamersley example (Geomodeller)\n",
    "\n",
    "This notebook reads in three layers from  local or remote sources:  geology polygons, orientation data and fault polylines; and calculates the topological relationships between the different features. Requires compiled cpp code from Vitaliy Ogarko\n",
    "\n",
    "This all gets fed into successive tolopogical and geometric transfroms that end up feeding into geomodeller to make a 3D model \n",
    "<img src='../graphics/map_sm.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:29:43.461289Z",
     "start_time": "2020-01-17T02:29:24.823138Z"
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory \n",
      "*** C:\\Program Files\\PostgreSQL\\11\\gdal-data\n",
      "is dir: True\n",
      "is file: True\n",
      "is readable: True\n",
      "C:\\\\Users\\\\00073294\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Lib\\\\site-packages\\\\pyproj\\\\proj_dir\\\\share\\\\proj\n",
      "C:\\Users\\00073294\\Dropbox\\1_Jupyter_notebooks\\map2loop\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import stat\n",
    "import functools \n",
    "import operator  \n",
    "import matplotlib\n",
    "import networkx as nx\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "from map2loop import m2l_utils\n",
    "from map2loop import m2l_topology\n",
    "from map2loop import m2l_geometry\n",
    "from map2loop import m2l_interpolation\n",
    "from map2loop import m2l_export\n",
    "%matplotlib inline\n",
    "\n",
    "#newwd=\"C:\\\\Users\\\\00073294\\Dropbox\\\\loop_minex\\\\map2model\\\\\"\n",
    "#os.chdir(newwd)\n",
    "print(\"Current Working Directory \" )\n",
    "\n",
    "gdal_data = os.environ['GDAL_DATA']\n",
    "print(\"***\",gdal_data)\n",
    "print('is dir: ' + str(os.path.isdir(gdal_data)))\n",
    "gcs_csv = os.path.join(gdal_data, 'gcs.csv')\n",
    "print('is file: ' + str(os.path.isfile(gcs_csv)))\n",
    "st = os.stat(gcs_csv)\n",
    "print('is readable: ' + str(bool(st.st_mode & stat.S_IRGRP)))\n",
    "os.environ['PROJ_LIB']=r\"C:\\\\Users\\\\00073294\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Lib\\\\site-packages\\\\pyproj\\\\proj_dir\\\\share\\\\proj\"\n",
    "print(os.getenv('PROJ_LIB'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bounding box based on inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:29:43.488217Z",
     "start_time": "2020-01-17T02:29:43.464282Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters loaded from ../test_data3/m2l_config.py:\n",
      "#ROI\n",
      "\n",
      "step_out=0.1   #padding arounf dtm to ensure reprojected dtm covers target area (in degrees)\n",
      "inset=0      #unused??\n",
      "\n",
      "minx=500057  #region of interest coordinates in metre-based system (or non-degree system)\n",
      "maxx=603028\n",
      "miny=7455348\n",
      "maxy=7567953\n",
      "model_top=1200\n",
      "model_base=-8200\n",
      "\n",
      "#PATHS\n",
      "\n",
      "local_paths=True       #flag to use local or WFS source for data inputs (True = local)\n",
      "\n",
      "test_data_path='../test_data3/'\n",
      "m2m_cpp_path='../m2m_cpp/'\n",
      "\n",
      "geology_file='hams2_geol.shp'   #input geology file (if local)\n",
      "fault_file='GEOS_GEOLOGY_LINEARSTRUCTURE_500K_GSD.shp' #input fault file (if local)\n",
      "structure_file='hams2_structure.shp' #input bedding orientation file (if local)\n",
      "mindep_file='mindeps_2018.shp' #input mineral deposit file (if local)\n",
      "\n",
      "\n",
      "#CRS\n",
      "\n",
      "src_crs = {'init': 'EPSG:4326'}  # coordinate reference system for imported dtms (geodetic lat/long WGS84)\n",
      "dst_crs = {'init': 'EPSG:28350'} # coordinate system for data\n",
      "\n",
      "#codes and labels these refer to specific fields (codes) in GIS layer or database that contain the info needed for these calcs and text substrings (labels) in the contents of these fields\n",
      "c_l= {\n",
      "#Orientations\n",
      "  \"d\": \"DIP\",                  #field that contains dip information\n",
      "  \"dd\": \"DIP_DIR\",             #field that contains dip direction information\n",
      "  \"sf\": 'FEATURE',             #field that contains information on type of structure\n",
      "  \"bedding\": 'Bed',            #text to search for in field defined by sf code to show that this is a bedding measurement\n",
      "#Stratigraphy\n",
      "  \"g\": 'GROUP_',               #field that contains coarser stratigraphic coding\n",
      "  \"c\": 'CODE',                 #field that contains finer stratigraphic coding\n",
      "  \"ds\": 'DESCRIPTN',           #field that contains information about lithology\n",
      "  \"u\": 'UNITNAME',             #field that contains alternate stratigraphic coding (not used??)\n",
      "  \"r1\": 'ROCKTYPE1',           #field that contains  extra lithology information\n",
      "  \"r2\": 'ROCKTYPE2',           #field that contains even more lithology information\n",
      "  \"sill\": 'sill',              #text to search for in field defined by ds code to show that this is a sill\n",
      "  \"intrusive\": 'intrusive',    #text to search for in field defined by ds code to show that this is an intrusion\n",
      "  \"volcanic\": 'volcanic',      #text to search for in field defined by ds code to show that this is an intrusion\n",
      "#Mineral Deposits\n",
      "  \"msc\": 'SITE_CODE',          #field that contains site code of deposit\n",
      "  \"msn\": 'SHORT_NAME',         #field that contains short name of deposit\n",
      "  \"mst\": 'SITE_TYPE_',         #field that contains site type of deposit\n",
      "  \"mtc\": 'TARGET_COM',         #field that contains target commodity of deposit\n",
      "  \"mscm\": 'SITE_COMMO',        #field that contains site commodity of deposit\n",
      "  \"mcom\": 'COMMODITY_',        #field that contains commodity group of deposit\n",
      "  \"minf\": 'Infrastructure',    #text to search for in field defined by mst code that shows site to ignore\n",
      "#Timing\n",
      "  \"min\": 'MIN_AGE_MA',         #field that contains minimum age of unit defined by ccode\n",
      "  \"max\": 'MAX_AGE_MA',         #field that contains maximum age of unit defined by ccode\n",
      "#faults and folds\n",
      "  \"f\": 'FEATURE',              #field that contains information on type of structure\n",
      "  \"fault\": 'Fault',            #text to search for in field defined by f code to show that this is a fault\n",
      "  \"fold\": 'Fold axial trace',  #text to search for in field defined by f code to show that this is a fold axial trace\n",
      "  \"n\": 'NAME',                 #field that contains information on name of fault (not used??)\n",
      "  \"t\": 'TYPE',                 #field that contains information on type of fold\n",
      "  \"syn\": 'syncline',           #text to search for in field defined by t to show that this is a syncline\n",
      "#ids\n",
      "  \"o\": 'OBJECTID',             #field that contains unique id of geometry object\n",
      "  \"gi\": 'GEOPNT_ID'            #field that contains unique id of structure point\n",
      "}\n",
      "\n",
      "#DECIMATION\n",
      "\n",
      "orientation_decimate=0  #store every nth orientation (in object order) 0 = save all\n",
      "contact_decimate=10     #store every nth contact point (in object order) 0 = save all\n",
      "fault_decimate=5        #store every nth fault point (in object order) 0 = save all\n",
      "fold_decimate=5         #store every nth fold axial trace point (in object order) 0 = save all\n",
      "\n",
      "\n",
      "#INTERPOLATION\n",
      "\n",
      "gridx=50                #x grid dimensions (no of points, not distance) for interpolations\n",
      "gridy=50                #x grid dimensions (no of points, not distance) for interpolations\n",
      "scheme='scipy_rbf'      #interpolation scheme\n",
      "dist_buffer=5           #buffer distance for clipping points by faults (in metres or same units as dst_crs)\n",
      "intrusion_mode=0        # 1 all intrusions exluded from basal contacts, 0 only sills\n",
      "use_interpolations=False    # flag to sue interpolated orientations or not.\n",
      "\n",
      "#ASSUMPTIONS\n",
      "\n",
      "pluton_dip=45           #surface dip of pluton contacts\n",
      "pluton_form='domes'     #saucers: \\__+_+__/  batholith: +/       \\+   domes: /  +  + \\  pendant: +\\_____/+\n",
      "fault_dip=90            #surface dip of faults\n",
      "\n",
      "#DERIVED PATHS\n",
      "\n",
      "\n",
      "graph_path=test_data_path+'graph/'\n",
      "tmp_path=test_data_path+'tmp/'\n",
      "data_path=test_data_path+'data/'\n",
      "dtm_path=test_data_path+'dtm/'\n",
      "output_path=test_data_path+'output/'\n",
      "vtk_path=test_data_path+'vtk/'\n",
      "\n",
      "fault_file=data_path+fault_file\n",
      "structure_file=data_path+structure_file\n",
      "geology_file=data_path+geology_file\n",
      "mindep_file=data_path+mindep_file\n",
      "\n",
      "fault_file_csv=fault_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "structure_file_csv=structure_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "geology_file_csv=geology_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "mindep_file_csv=mindep_file.replace(\".shp\",\".csv\").replace(\"/data/\",\"/tmp/\")\n",
      "\n",
      "strat_graph_file=test_data_path+'graph/graph_strat.gml'\n",
      "\n",
      "dtm_file=dtm_path+'dtm.tif'\n",
      "dtm_reproj_file=dtm_path+'dtm_rp.tif'\n",
      "\n",
      "if(not os.path.isdir(test_data_path)):\n",
      "   os.mkdir(test_data_path)\n",
      "if(not os.path.isdir(tmp_path)):\n",
      "   os.mkdir(tmp_path)\n",
      "if(not os.path.isdir(output_path)):\n",
      "   os.mkdir(output_path)\n",
      "if(not os.path.isdir(dtm_path)):\n",
      "   os.mkdir(dtm_path)\n",
      "if(not os.path.isdir(vtk_path)):\n",
      "   os.mkdir(vtk_path)\n",
      "if(not os.path.isdir(graph_path)):\n",
      "   os.mkdir(graph_path)\n",
      "\n",
      "print('Default parameters loaded from '+test_data_path+'m2l_config.py:')\n",
      "with open(test_data_path+'m2l_config.py', 'r') as myfile:\n",
      "  data = myfile.read()\n",
      "  print(data)\n",
      "  myfile.close()\n",
      "\n",
      "print('\\nModify these parameters in the cell below')\n",
      "\n",
      "Modify these parameters in the cell below\n",
      "C:\\Users\\00073294\\Dropbox\\1_Jupyter_notebooks\\map2loop\\test_data3\n"
     ]
    }
   ],
   "source": [
    "test_data_name='test_data3'\n",
    "\n",
    "test_data_path='../'+test_data_name+'/'\n",
    "\n",
    "os.chdir(test_data_path)\n",
    "%run -i \"m2l_config.py\"\n",
    "#%run -i \"m2l_config_remote.py\"\n",
    "print(os.getcwd())\n",
    "\n",
    "bbox2=str(minx)+\",\"+str(miny)+\",\"+str(maxx)+\",\"+str(maxy)\n",
    "lat_point_list = [miny, miny, maxy, maxy, maxy]\n",
    "lon_point_list = [minx, maxx, maxx, minx, minx]\n",
    "bbox_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "polygon = gpd.GeoDataFrame(index=[0], crs=dst_crs, geometry=[bbox_geom]) \n",
    "bbox=(minx,miny,maxx,maxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:29:43.501184Z",
     "start_time": "2020-01-17T02:29:43.494204Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fold_decimate=2         \n",
    "\n",
    "contact_decimate=5\n",
    "\n",
    "use_interpolations=True       #use interpolated dips/contacts as additional constraints\n",
    "\n",
    "use_fat=True                   #use fold axial trace orientation hints\n",
    "\n",
    "pluton_form='domes'\n",
    "\n",
    "fault_dip=-999\n",
    "\n",
    "min_fault_length=5000\n",
    "\n",
    "compute_etc=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data to ensure it meets modelling requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:30:09.787876Z",
     "start_time": "2020-01-17T02:29:43.508166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only processing ('Hamersley_Group', 'Fortescue_Group', 'Turee_Creek_Group', 'A_mgn_PRK', 'A_mgn_PMI')\n"
     ]
    }
   ],
   "source": [
    "if(local_paths): ###############FUDGE#############\n",
    "    use_gcode=('Hamersley_Group','Fortescue_Group','Turee_Creek_Group','A_mgn_PRK',  'A_mgn_PMI' ) ################# MOVE UP   #########################\n",
    "    #use_gcode=('Hamersley_Group','Fortescue_Group','Wyloo_Group','Shingle_Creek_Group','Turee_Creek_Group','A_mgn_PRK',  'A_mgn_PMI' ) ################# MOVE UP   #########################\n",
    "else:\n",
    "    use_gcode=('Hamersley_Group','Fortescue_Group','Wyloo_Group','Shingle_Creek_Group','Turee_Creek_Group','A_mgn_PMI',  'A_mgn_PRK' ) ################# MOVE UP   #########################\n",
    "\n",
    "\n",
    "print('only processing',use_gcode)\n",
    "\n",
    "#inputs=('invented_orientations','interpolated_orientations','intrusive_orientations','fat_orientations','near_fault_orientations')\n",
    "#inputs=('invented_orientations','interpolated_orientations','intrusive_orientations','fat_orientations','near_fault_orientations')\n",
    "inputs=('invented_orientations','intrusive_orientations','fat_orientations','near_fault_orientations')\n",
    "\n",
    "m2l_geometry.tidy_data(output_path,tmp_path,use_gcode,use_interpolations,use_fat,pluton_form,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# loop2gemodeller test \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:30:50.621665Z",
     "start_time": "2020-01-17T02:30:09.790916Z"
    }
   },
   "outputs": [],
   "source": [
    "save_faults=True\n",
    "compute_etc=True\n",
    "\n",
    "m2l_export.loop2geomodeller(test_data_path,tmp_path,output_path,'./dtm/dtm_rp.tif',bbox,save_faults,compute_etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:31:23.738092Z",
     "start_time": "2020-01-17T02:30:50.627649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WARNING: An illegal reflective access operation has occurred',\n",
       " 'WARNING: Illegal reflective access by com.dfa.util.Lib (file:/C:/GeoModeller/GeoModeller4.0.8_x64_88b64e610d9/bin/plugins/au.com.dfa.intrepid.lib_6.0.0.201911202221.jar) to field java.lang.ClassLoader.loadedLibraryNames',\n",
       " 'WARNING: Please consider reporting this to the maintainers of com.dfa.util.Lib',\n",
       " 'WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations',\n",
       " 'WARNING: All illegal access operations will be denied in a future release',\n",
       " 'COMPOSE EXTRA LENGTH FOR A_mgn_PRK 0',\n",
       " 'COMPOSE EXTRA LENGTH FOR A_mgn_PMI 0',\n",
       " 'COMPOSE EXTRA LENGTH FOR Fortescue_Group 0',\n",
       " 'COMPOSE EXTRA LENGTH FOR Hamersley_Group 0',\n",
       " 'COMPOSE EXTRA LENGTH FOR Turee_Creek_Group 0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(test_data_path)\n",
    "%system geomodellerbatch.exe -batch m2l.taskfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:31:23.747068Z",
     "start_time": "2020-01-17T02:31:23.742082Z"
    }
   },
   "outputs": [],
   "source": [
    "#%system geomodellerbatch.exe -batch m2l_compute.taskfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T02:31:25.775535Z",
     "start_time": "2020-01-17T02:31:23.753102Z"
    }
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 500  # milliseconds\n",
    "freq = 1100  # Hz\n",
    "winsound.Beep(freq, duration)\n",
    "winsound.Beep(freq, duration)\n",
    "duration=999\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
