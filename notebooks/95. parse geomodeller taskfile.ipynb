{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple parser for geomodeller taskfile (exported as 3D contacts and orientations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:50.754348Z",
     "start_time": "2020-04-13T04:10:50.706477Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path='../fabiele/Models_Prelim/'\n",
    "root_name='from_fabiele'\n",
    "taskfile_path=path+root_name+'.task'\n",
    "tasks=open(taskfile_path,\"r\")\n",
    "contents =tasks.readlines()\n",
    "tasks.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse 3D Interface Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:52.872943Z",
     "start_time": "2020-04-13T04:10:52.732317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Malu\"\n",
      " \"Puntapunta\"\n",
      " \"Wilki\"\n",
      " \"Coolbro\"\n",
      " \"Isdell\"\n",
      " \"Broadhurst\"\n",
      " \"Dummy\"\n",
      " \"Wilki_1\"\n",
      " \"Wilki_2\"\n",
      " \"Wilki_3\"\n",
      " \"SZ_PR\"\n",
      " \"Parallel_Range_S\"\n",
      " \"Parallel_Range_N\"\n",
      " \"West_Waukarlycarly\"\n",
      " \"Vines\"\n",
      " \"Rudall\"\n",
      " \"Telfer_E\"\n",
      " \"Telfer_W\"\n",
      " \"Anketel\"\n",
      " \"Officer\"\n",
      " \"R1\"\n",
      " \"R2\"\n",
      " \"R3\"\n",
      " \"R4\"\n",
      " \"R5\"\n",
      " \"R6\"\n",
      " \"T1\"\n",
      " \"T2\"\n",
      " \"T3\"\n",
      " \"T4\"\n",
      " \"T5\"\n",
      " \"T6\"\n",
      " \"T7\"\n",
      " \"T8\"\n",
      " \"T9\"\n",
      " \"T10\"\n",
      " \"Officer_Vines\"\n",
      " \"Anketel_1\"\n",
      " \"SZ_anketel\"\n",
      " \"Anketel_1B\"\n",
      " \"OChallaghans_1\"\n",
      " \"Mt_Crofton_1\"\n",
      " \"Mt_Crofton_2\"\n",
      " \"Mt_Crofton_3\"\n",
      " \"Mt_Crofton_4\"\n",
      " \"Mt_Crofton_5\"\n",
      " \"Mt_Crofton_7\"\n",
      " \"Mt_Crofton_6\"\n",
      " \"OChallaghans_2\"\n",
      " \"OChallaghans_3\"\n",
      " \"OChallaghans_4\"\n",
      " \"OChallaghans_5\"\n",
      " \"OChallaghans_6\"\n",
      " \"OChallaghans_7\"\n",
      " \"OChallaghans_8\"\n",
      " \"OChallaghans_9\"\n",
      " \"OChallaghans_10\"\n",
      " \"OChallaghans_11\"\n",
      " \"OChallaghans_12\"\n",
      " \"Cover\"\n",
      " \"Coolbro\"\n",
      " \"Broadhurst\"\n",
      " \"Officer\"\n",
      " \"Malu\"\n",
      " \"Isdell\"\n",
      " \"Wilki\"\n",
      " \"Puntapunta\"\n",
      " \"Pilbara\"\n",
      " \"Cover\"\n"
     ]
    }
   ],
   "source": [
    "allc=open(path+root_name+'_contacts.csv',\"w\")\n",
    "allc.write('x,y,z,formation\\n')\n",
    "i=0\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('Add3DInterfacesToFormation' in contents[i+1]):\n",
    "            for j in range(i+2,len(contents),5):\n",
    "                if('formation' in contents[j]):\n",
    "                    formation=contents[j].split(\":\")\n",
    "                    print(formation[1].replace(\"\\n\",\"\"))\n",
    "                    break\n",
    "            for j in range(i+2,len(contents),5):\n",
    "                if('point' in contents[j]):\n",
    "                    x=contents[j+1].split(\":\")\n",
    "                    y=contents[j+2].split(\":\")\n",
    "                    z=contents[j+3].split(\":\")\n",
    "                    ostr=str(x[1].replace(\"\\n\",\"\"))+','+str(y[1].replace(\"\\n\",\"\"))+','+str(z[1].replace(\"\\n\",\"\"))+','+str(formation[1].replace(\"\\n\",\"\").replace('\"',''))+'\\n'\n",
    "                    allc.write(ostr)\n",
    "                    #print(formation[1],x[1],y[1],z[1])\n",
    "                else:\n",
    "                    break\n",
    "    i=i+1\n",
    "allc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse 3D Foliation Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:54.859647Z",
     "start_time": "2020-04-13T04:10:54.779860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Malu\"\n",
      " \"Puntapunta\"\n",
      " \"Wilki\"\n",
      " \"Coolbro\"\n",
      " \"Isdell\"\n",
      " \"Broadhurst\"\n",
      " \"Dummy\"\n",
      " \"Wilki_1\"\n",
      " \"Wilki_2\"\n",
      " \"Wilki_3\"\n",
      " \"SZ_PR\"\n",
      " \"Parallel_Range_S\"\n",
      " \"Parallel_Range_N\"\n",
      " \"West_Waukarlycarly\"\n",
      " \"Vines\"\n",
      " \"Rudall\"\n",
      " \"Telfer_E\"\n",
      " \"Telfer_W\"\n",
      " \"Anketel\"\n",
      " \"Officer\"\n",
      " \"R1\"\n",
      " \"R2\"\n",
      " \"R3\"\n",
      " \"R4\"\n",
      " \"R5\"\n",
      " \"R6\"\n",
      " \"T1\"\n",
      " \"T2\"\n",
      " \"T3\"\n",
      " \"T4\"\n",
      " \"T5\"\n",
      " \"T6\"\n",
      " \"T7\"\n",
      " \"T8\"\n",
      " \"T9\"\n",
      " \"T10\"\n",
      " \"Officer_Vines\"\n",
      " \"Anketel_1\"\n",
      " \"SZ_anketel\"\n",
      " \"Anketel_1B\"\n",
      " \"OChallaghans_1\"\n",
      " \"Mt_Crofton_1\"\n",
      " \"Mt_Crofton_2\"\n",
      " \"Mt_Crofton_3\"\n",
      " \"Mt_Crofton_4\"\n",
      " \"Mt_Crofton_5\"\n",
      " \"Mt_Crofton_7\"\n",
      " \"Mt_Crofton_6\"\n",
      " \"OChallaghans_2\"\n",
      " \"OChallaghans_3\"\n",
      " \"OChallaghans_4\"\n",
      " \"OChallaghans_5\"\n",
      " \"OChallaghans_6\"\n",
      " \"OChallaghans_7\"\n",
      " \"OChallaghans_8\"\n",
      " \"OChallaghans_9\"\n",
      " \"OChallaghans_10\"\n",
      " \"OChallaghans_11\"\n",
      " \"OChallaghans_12\"\n",
      " \"Cover\"\n"
     ]
    }
   ],
   "source": [
    "allo=open(path+root_name+'_orientations.csv',\"w\")\n",
    "allo.write('x,y,z,azimuth,dip,polarity,formation\\n')\n",
    "i=0\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('Add3DFoliationToFormation' in contents[i+1]):\n",
    "            formation=contents[i+2].split(\":\")\n",
    "            formation=formation[1].replace(\"\\n\",\"\")\n",
    "            print(formation)\n",
    "            \n",
    "            for j in range(i+3,len(contents),10):\n",
    "                if('foliation' in contents[j]):\n",
    "                    x=contents[j+2].split(\":\")\n",
    "                    y=contents[j+3].split(\":\")\n",
    "                    z=contents[j+4].split(\":\")\n",
    "                    dip=contents[j+6].split(\":\")\n",
    "                    dipdir=contents[j+7].split(\":\")\n",
    "                    azimuth=contents[j+8].split(\":\")\n",
    "                    polarity=contents[j+9].split(\":\")\n",
    "                    polarity=polarity[1].replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    if(polarity=='Normal_Polarity'):\n",
    "                        polarity=1\n",
    "                    else:\n",
    "                        polarity=0\n",
    "                    ostr=str(x[1].replace(\"\\n\",\"\"))+','+str(y[1].replace(\"\\n\",\"\"))+','+str(z[1].replace(\"\\n\",\"\"))+','+str(azimuth[1].replace(\"\\n\",\"\"))+','+str(dip[1].replace(\"\\n\",\"\"))+','+str(polarity)+','+str(formation.replace('\"',''))+'\\n'\n",
    "                    allo.write(ostr)\n",
    "                    #print(x[1],y[1],z[1],azimuth[1],dip[1],polarity,formation[1])\n",
    "                else:\n",
    "                    break\n",
    "    i=i+1\n",
    "allo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse stratigraphy Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:56.239279Z",
     "start_time": "2020-04-13T04:10:56.174435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilbara_Series\n",
      "Rudall_Series\n",
      "Throssel\n",
      "Isdell_Series\n",
      "Lamil\n",
      "Mt_Crofton_1_Series\n",
      "Mt_Crofton_2_Series\n",
      "Mt_Crofton_3_Series\n",
      "Mt_Crofton_4_Series\n",
      "Mt_Crofton_5_Series\n",
      "Mt_Crofton_6_Series\n",
      "Mt_Crofton_7_Series\n",
      "OChallaghans_1_Series\n",
      "OChallaghans_2_Series\n",
      "OChallaghans_3_Series\n",
      "OChallaghans_4_Series\n",
      "OChallaghans_5_Series\n",
      "OChallaghans_6_Series\n",
      "OChallaghans_7_Series\n",
      "OChallaghans_8_Series\n",
      "OChallaghans_9_Series\n",
      "OChallaghans_10_Series\n",
      "OChallaghans_11_Series\n",
      "OChallaghans_12_Series\n",
      "Officer_Series\n",
      "Cover_Series\n"
     ]
    }
   ],
   "source": [
    "alls=open(path+root_name+'_strat.csv',\"w\")\n",
    "alls.write('type,series,formation,relation\\n')\n",
    "i=0\n",
    "\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('SetSeries' in contents[i+1]):\n",
    "            series=contents[i+2].split(\":\")\n",
    "            series=series[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "            position=contents[i+3].split(\":\")\n",
    "            position=position[1].replace(\"\\n\",\"\")\n",
    "            relation=contents[i+4].split(\":\")\n",
    "            relation=relation[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "            print(series)\n",
    "            ostr=str(\"0\")+','+str(series)+','+str(\" \")+','+str(relation)+'\\n'\n",
    "            alls.write(ostr)\n",
    "            \n",
    "            for j in range(i+8,len(contents),6):\n",
    "                if('AddFormationToSeries' in contents[j]):\n",
    "                    formation=contents[j+2].split(\":\")\n",
    "                    formation=formation[1].replace(\"\\n\",\"\").replace('\"','').replace(\" \",\"\")\n",
    "                    ostr=str(\"1\")+','+str(series)+','+str(formation)+','+str(\" \")+'\\n'\n",
    "                    alls.write(ostr)\n",
    "                    #print(x[1],y[1],z[1],azimuth[1],dip[1],polarity,formation[1])\n",
    "                else:\n",
    "                    break\n",
    "    i=i+1\n",
    "\n",
    "alls.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Fault Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:58.063414Z",
     "start_time": "2020-04-13T04:10:57.988613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anketel  255\n",
      "Anketel_1  255\n",
      "Anketel_1B  112\n",
      "Officer_Vines  105\n",
      "Parallel_Range_N  137\n",
      "Parallel_Range_S  137\n",
      "R1  45\n",
      "R2  0\n",
      "R3  255\n",
      "R4  63\n",
      "R5  0\n",
      "R6  255\n",
      "SZ_PR  255\n",
      "SZ_anketel  0\n",
      "T1  196\n",
      "T10  255\n",
      "T2  167\n",
      "T3  144\n",
      "T4  119\n",
      "T5  255\n",
      "T6  205\n",
      "T7  205\n",
      "T8  237\n",
      "T9  167\n",
      "Telfer_E  0\n",
      "Telfer_W  68\n",
      "Vines  0\n",
      "West_Waukarlycarly  138\n",
      "Wilki_1  255\n",
      "Wilki_2  255\n",
      "Wilki_3  255\n"
     ]
    }
   ],
   "source": [
    "allf=open(path+root_name+'_fault.csv',\"w\")\n",
    "allf.write('fault_name,red,green,blue,thickness,horizontal,vertical,influedistance,type\\n')\n",
    "i=0\n",
    "\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('CreateFault' in contents[i+1]):\n",
    "            faultname=contents[i+2].split(\":\")\n",
    "            faultname=faultname[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "            red=contents[i+3].split(\":\")\n",
    "            red=red[1].replace(\"\\n\",\"\")\n",
    "            green=contents[i+4].split(\":\")\n",
    "            green=green[1].replace(\"\\n\",\"\")\n",
    "            blue=contents[i+5].split(\":\")\n",
    "            blue=blue[1].replace(\"\\n\",\"\")\n",
    "            thickness=contents[i+6].split(\":\")\n",
    "            thickness=thickness[1].replace(\"\\n\",\"\")\n",
    "            print(faultname,blue)\n",
    "            \n",
    "            if('Set3dFaultLimits' in contents[i+8]):\n",
    "                horizontal=contents[i+10].split(\":\")\n",
    "                horizontal=horizontal[1].replace(\"\\n\",\"\")\n",
    "                vertical=contents[i+11].split(\":\")\n",
    "                vertical=vertical[1].replace(\"\\n\",\"\")\n",
    "                influedistance=contents[i+12].split(\":\")\n",
    "                influedistance=influedistance[1].replace(\"\\n\",\"\")\n",
    "                if('fault_centre' in contents[i+14]):\n",
    "                    typef=contents[i+16].split(\":\")\n",
    "                    typef=typef[1].replace(\"\\n\",\"\")\n",
    "                else:\n",
    "                    typef=''\n",
    "            elif('fault_centre' in contents[i+8]):\n",
    "                typef=contents[i+10].split(\":\")\n",
    "                typef=typef[1].replace(\"\\n\",\"\")\n",
    "                horizontal=0\n",
    "                vertical=0\n",
    "                influedistance=0\n",
    "            \n",
    "            ostr=str(faultname)+','+str(red)+','+str(green)+','+str(blue)+','+str(thickness)+','+str(horizontal)+','+str(vertical)+','+str(influedistance)+','+str(typef)+'\\n'\n",
    "            allf.write(ostr)\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "allf.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Fault topology Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:10:59.452006Z",
     "start_time": "2020-04-13T04:10:59.359252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anketel_1\n",
      "Anketel_1B\n",
      "Officer_Vines\n",
      "Parallel_Range_N\n",
      "Parallel_Range_S\n",
      "R1\n",
      "R5\n",
      "T1\n",
      "T10\n",
      "T2\n",
      "T3\n",
      "T5\n",
      "T6\n",
      "T7\n",
      "T8\n",
      "T9\n",
      "Telfer_W\n"
     ]
    }
   ],
   "source": [
    "allfs=open(path+root_name+'_fault_topology.csv',\"w\")\n",
    "allfs.write('fault_name,stops_on_faults\\n')\n",
    "i=0\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('LinkFaultsWithFaults' in contents[i+1]):\n",
    "            inc=i+2\n",
    "            while('FaultStopsOnFaults' in contents[inc]):\n",
    "                fault=contents[inc+1].split(\":\")\n",
    "                fault=fault[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                print(fault.replace(\"\\n\",\"\"))\n",
    "                ostr=str(fault)+','\n",
    "                allfs.write(ostr)\n",
    "                for k in range (inc+2,len(contents)):\n",
    "                    if('stopson' in contents[k]):\n",
    "                        faulton=contents[k].split(\":\")\n",
    "                        faulton=faulton[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        ostr=str(faulton)+';'\n",
    "                        allfs.write(ostr)\n",
    "                        inc=inc+1\n",
    "                    else:\n",
    "                        ostr='\\n'\n",
    "                        allfs.write(ostr)\n",
    "                        break\n",
    "                inc=inc+3\n",
    "        \n",
    "    i=i+1\n",
    "\n",
    "allfs.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Fault Series topology Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:11:00.916100Z",
     "start_time": "2020-04-13T04:11:00.812377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anketel\n",
      "Anketel_1\n",
      "Anketel_1B\n",
      "Officer_Vines\n",
      "Parallel_Range_N\n",
      "Parallel_Range_S\n",
      "R1\n",
      "R2\n",
      "R3\n",
      "R4\n",
      "R5\n",
      "R6\n",
      "SZ_PR\n",
      "SZ_anketel\n",
      "T1\n",
      "T10\n",
      "T2\n",
      "T3\n",
      "T4\n",
      "T5\n",
      "T6\n",
      "T7\n",
      "T8\n",
      "T9\n",
      "Telfer_E\n",
      "Telfer_W\n",
      "Vines\n",
      "West_Waukarlycarly\n",
      "Wilki_1\n",
      "Wilki_2\n",
      "Wilki_3\n"
     ]
    }
   ],
   "source": [
    "allfse=open(path+root_name+'_fault_series_topology.csv',\"w\")\n",
    "allfse.write('fault_name,series_stops_on_faults\\n')\n",
    "i=0\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('LinkFaultsWithSeries' in contents[i+1]):\n",
    "            inc=i+2\n",
    "            while('FaultSeriesLinks' in contents[inc]):\n",
    "                fault=contents[inc+1].split(\":\")\n",
    "                fault=fault[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                print(fault.replace(\"\\n\",\"\"))\n",
    "                ostr=str(fault)+','\n",
    "                allfse.write(ostr)\n",
    "                for k in range (inc+2,len(contents)):\n",
    "                    if('series' in contents[k]):\n",
    "                        faulton=contents[k].split(\":\")\n",
    "                        faulton=faulton[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        ostr=str(faulton)+';'\n",
    "                        allfse.write(ostr)\n",
    "                        inc=inc+1\n",
    "                    else:\n",
    "                        ostr='\\n'\n",
    "                        allfse.write(ostr)\n",
    "                        break\n",
    "                inc=inc+3\n",
    "        \n",
    "    i=i+1\n",
    "\n",
    "allfse.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:11:02.658135Z",
     "start_time": "2020-04-13T04:11:02.295103Z"
    }
   },
   "outputs": [],
   "source": [
    "allmeta=open(path+root_name+'_metadata.csv',\"w\")\n",
    "allmeta.write('property,value\\n')\n",
    "i=0\n",
    "keywords=('Grid_Name','map_projection', 'referenceTop','author','date')\n",
    "first=True\n",
    "firstname=True\n",
    "for line in contents:\n",
    "    if('name' in line and firstname==True):\n",
    "        firstname=False\n",
    "        text=line.split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+',\"'+str(text[2].replace(\"\\n\",\"\").replace(\" \",\"\").replace(\"\\\\\",\"\").replace('\"',''))+'\"\\n'\n",
    "        allmeta.write(ostr)\n",
    "        \n",
    "    kw=line.split(\":\")\n",
    "    kw=kw[0].replace(\" \",\"\")\n",
    "    if(kw in keywords):\n",
    "        if('date' in line):\n",
    "            text=line.split(\":\")\n",
    "            ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+':'+str(text[2].replace(\"\\n\",\"\"))+':'+str(text[3].replace(\"\\n\",\"\"))+'\\n'\n",
    "            allmeta.write(ostr)\n",
    "        else:\n",
    "            text=line.split(\":\")\n",
    "            ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "            allmeta.write(ostr)\n",
    "        \n",
    "    if( 'zmax' in line and first==True):\n",
    "        first=False\n",
    "        text=contents[i-5].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "        text=contents[i-4].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "        text=contents[i-3].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "        text=contents[i-2].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "        text=contents[i-1].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "        text=contents[i].split(\":\")\n",
    "        ostr=str(text[0].replace(\" \",\"\"))+','+str(text[1].replace(\"\\n\",\"\"))+'\\n'\n",
    "        allmeta.write(ostr)\n",
    "    i=i+1\n",
    "        \n",
    "allmeta.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Petrophysics info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:11:04.663789Z",
     "start_time": "2020-04-13T04:11:04.461330Z"
    }
   },
   "outputs": [],
   "source": [
    "allp=open(path+root_name+'_petrophsyics.csv',\"w\")\n",
    "allp.write('formation,property,disttype,mean,stddev,inc,dec,percentage\\n')\n",
    "i=0\n",
    "for line in contents:\n",
    "    if( 'GeomodellerTask {' in line):\n",
    "        if('CreateFormation' in contents[i+1]):\n",
    "            inc=i+6\n",
    "            inc2=0\n",
    "            while('LithologyProperty' in contents[inc]):\n",
    "                inc2=0\n",
    "                k=inc+3\n",
    "                property=disttype=mean=stddev=incl=dec=percentage=0\n",
    "                if('ProbabilityDistributionFunction' in contents[k]):       #density 1\n",
    "                    formation=contents[k-2].split(\":\")\n",
    "                    formation=formation[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    prop=contents[k-1].split(\":\")\n",
    "                    prop=prop[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    print()\n",
    "                    print(formation)\n",
    "                    print(prop)\n",
    "                    disttype=contents[k+1].split(\":\")\n",
    "                    disttype=disttype[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    mean=contents[k+2].split(\":\")\n",
    "                    mean=mean[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    stddev=contents[k+3].split(\":\")\n",
    "                    stddev=stddev[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    if(prop=='Remanence'):\n",
    "                        inc=contents[k+4].split(\":\")\n",
    "                        inc=inc[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        dec=contents[k+5].split(\":\")\n",
    "                        dec=dec[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        inc2=2\n",
    "                    percentage=contents[k+4+inc2].split(\":\")\n",
    "                    percentage=percentage[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    ostr=str(formation)+','+str(prop)+','+str(disttype)+','+str(mean)+','+str(stddev)+','+str(incl)+','+str(dec)+','+str(percentage)+','+'\\n'\n",
    "                    allp.write(ostr)\n",
    "                    #print(mean)\n",
    "                    \n",
    "                    k=k+10       \n",
    "                    \n",
    "                inc2=0\n",
    "                if(int(percentage)<100):        #density 2\n",
    "                    k=k-4\n",
    "                    print(prop)\n",
    "                    disttype=contents[k+1].split(\":\")\n",
    "                    disttype=disttype[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    mean=contents[k+2].split(\":\")\n",
    "                    mean=mean[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    stddev=contents[k+3].split(\":\")\n",
    "                    stddev=stddev[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    if(prop=='Remanence'):\n",
    "                        inc=contents[k+4].split(\":\")\n",
    "                        inc=inc[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        dec=contents[k+5].split(\":\")\n",
    "                        dec=dec[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        inc2=2\n",
    "                    percentage=contents[k+4+inc2].split(\":\")\n",
    "                    percentage=percentage[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    ostr=str(formation)+','+str(prop)+','+str(disttype)+','+str(mean)+','+str(stddev)+','+str(incl)+','+str(dec)+','+str(percentage)+','+'\\n'\n",
    "                    allp.write(ostr)\n",
    "                    #print(mean)\n",
    "                    \n",
    "                    k=k+10                           \n",
    "                    \n",
    "                inc2=0\n",
    "                if('ProbabilityDistributionFunction' in contents[k]):  #mag sus 1\n",
    "                    formation=contents[k-2].split(\":\")\n",
    "                    formation=formation[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    prop=contents[k-1].split(\":\")\n",
    "                    prop=prop[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    print(prop)\n",
    "\n",
    "                    disttype=contents[k+1].split(\":\")\n",
    "                    disttype=disttype[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    mean=contents[k+2].split(\":\")\n",
    "                    mean=mean[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    stddev=contents[k+3].split(\":\")\n",
    "                    stddev=stddev[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    if(prop=='Remanence'):\n",
    "                        inc=contents[k+4].split(\":\")\n",
    "                        inc=inc[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        dec=contents[k+5].split(\":\")\n",
    "                        dec=dec[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        inc2=2\n",
    "                    percentage=contents[k+4+inc2].split(\":\")\n",
    "                    percentage=percentage[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    ostr=str(formation)+','+str(prop)+','+str(disttype)+','+str(mean)+','+str(stddev)+','+str(incl)+','+str(dec)+','+str(percentage)+','+'\\n'\n",
    "                    allp.write(ostr)\n",
    "                    #print(mean)\n",
    "                    \n",
    "                    k=k+10\n",
    "                \n",
    "                inc2=0\n",
    "                if(int(percentage)<100):        #mag sus 2\n",
    "                    k=k-4\n",
    "                    print(prop)\n",
    "                    disttype=contents[k+1].split(\":\")\n",
    "                    disttype=disttype[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    mean=contents[k+2].split(\":\")\n",
    "                    mean=mean[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    stddev=contents[k+3].split(\":\")\n",
    "                    stddev=stddev[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    if(prop=='Remanence'):\n",
    "                        inc=contents[k+4].split(\":\")\n",
    "                        inc=inc[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        dec=contents[k+5].split(\":\")\n",
    "                        dec=dec[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        inc2=2\n",
    "                    percentage=contents[k+4+inc2].split(\":\")\n",
    "                    percentage=percentage[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    ostr=str(formation)+','+str(prop)+','+str(disttype)+','+str(mean)+','+str(stddev)+','+str(incl)+','+str(dec)+','+str(percentage)+','+'\\n'\n",
    "                    allp.write(ostr)\n",
    "                    #print(mean)\n",
    "                    \n",
    "                    k=k+10       \n",
    "                    \n",
    "                inc2=0\n",
    "                if('ProbabilityDistributionFunction' in contents[k]):  #remanence\n",
    "                    formation=contents[k-2].split(\":\")\n",
    "                    formation=formation[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    prop=contents[k-1].split(\":\")\n",
    "                    prop=prop[1].replace('\"','').replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                    print(prop)\n",
    "\n",
    "                    disttype=contents[k+1].split(\":\")\n",
    "                    disttype=disttype[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    mean=contents[k+2].split(\":\")\n",
    "                    mean=mean[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    stddev=contents[k+3].split(\":\")\n",
    "                    stddev=stddev[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    if(prop=='Remanence'):\n",
    "                        incl=contents[k+4].split(\":\")\n",
    "                        incl=incl[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        dec=contents[k+5].split(\":\")\n",
    "                        dec=dec[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                        inc2=2\n",
    "                    percentage=contents[k+4+inc2].split(\":\")\n",
    "                    percentage=percentage[1].replace('\"','').replace(\"\\n\",\"\")\n",
    "                    ostr=str(formation)+','+str(prop)+','+str(disttype)+','+str(mean)+','+str(stddev)+','+str(incl)+','+str(dec)+','+str(percentage)+','+'\\n'\n",
    "                    allp.write(ostr)\n",
    "                    #print(mean)\n",
    "                    \n",
    "                    k=k+10\n",
    "                    \n",
    "                inc=inc+1\n",
    "\n",
    "   \n",
    "    i=i+1\n",
    "\n",
    "allp.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
